{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_hw2_tasks_1_2_functions_qa_performance.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7htgS3G-7LyF",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning Course\n",
        "\n",
        "### Homework 2\n",
        "\n",
        "### Task 1:\n",
        "    1.1. Implement SimpleConvNet’s layer’s conv2d_scalar, pool2d_scalar, relu_scalar, fc_layer_scalar (forward pass) in scalar form. \n",
        "    1.2. Ensure that all layer’s in-termediate outputs are exactly the same as in Pytorch framework.  You may use 'diff_mse' function for this purpose.\n",
        "    \n",
        "### Task 2:  \n",
        "    Implement SimpleConvNet’s layer’s (forward pass) in vector form. Please,use your derived equations from Homework I.\n",
        "    (a)  for the convolutional layer conv2d_vector described in section 2.1 in matrix form.  Column’s length in reshaped input matrix isCin∗K∗K.  \n",
        "    (b)  For  the  pooling  layer pool2d_vector\n",
        "    (c)  For the fully-connected layer described in section 2.4 fc_layer_vector.\n",
        "    \n",
        "### Task 3:\n",
        "    Train your network for 20 epochs, report the achieved accuracy on MNIST test data. Measure and report the time on one epoch for scalar and vector variants.\n",
        "    \n",
        "### Comments: In this notebook you can find task 1,2 and partly 3 (measured time on dummy data). For the rest of task 3, please, visit https://colab.research.google.com/drive/1aI3HH3Gj35HHsopXja6bP36Y1heE50Rm\n",
        "\n",
        "\n",
        " #### Anastasiia Kasprova\n",
        " \n",
        "    Link to github: https://github.com/kasprova/DL_UCU/tree/master/tasks/hw2\n",
        "    Link to google colab: https://colab.research.google.com/drive/1TMqoh8WRat9IsbrVJlDdMCfiuG6bxa90\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztbWzN80rF0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6bmRKsxrICd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def diff_mse(x, y):\n",
        "    x_vec = x.view(1, -1).squeeze()\n",
        "    y_vec = y.view(1, -1).squeeze()\n",
        "    return torch.mean(torch.pow((x_vec - y_vec), 2)).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9gLqU75p15-",
        "colab_type": "text"
      },
      "source": [
        "## Simple Convolutional Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKhulUH_vX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.device = device\n",
        "        self.conv_layer = nn.Conv2d(in_channels=1,\n",
        "                                    out_channels=20,\n",
        "                                    kernel_size=5,\n",
        "                                    stride=1,\n",
        "                                    padding=0,\n",
        "                                    dilation=1,\n",
        "                                    groups=1,\n",
        "                                    bias=True)\n",
        "\n",
        "        self.fc_layer1 = nn.Linear(in_features=20 * 12 * 12, out_features=500)\n",
        "        self.fc_layer2 = nn.Linear(in_features=500, out_features=10)\n",
        "        self.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LxtTHKQqGyj",
        "colab_type": "text"
      },
      "source": [
        "#### Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J83_1P-i_yl8",
        "colab_type": "code",
        "outputId": "34899c74-f717-4918-a2cc-04e2d67f02c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "no_cuda = False\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-aIM-SRBh4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiation of the model\n",
        "model = SimpleConvNet(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rc392lBqTo",
        "colab_type": "code",
        "outputId": "71075f8a-3833-4412-da43-cd44a137943f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleConvNet(\n",
              "  (conv_layer): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc_layer1): Linear(in_features=2880, out_features=500, bias=True)\n",
              "  (fc_layer2): Linear(in_features=500, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3RCKQplqQE7",
        "colab_type": "text"
      },
      "source": [
        "#### Parameters initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3MNhsidLNNDP",
        "colab": {}
      },
      "source": [
        "#conv_layer\n",
        "data = torch.rand([1,1,28,28]).requires_grad_(True) #batch_size=64 - crashed on fc1 layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJZEbHT38iBS",
        "colab_type": "text"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2LU86F898Fv",
        "colab_type": "text"
      },
      "source": [
        "##1. Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vXrNLa7_yEu",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1 Scalar form of equation of convolution:\n",
        "\\begin{equation}\n",
        "z_{n,c_{out},m,l}^{(conv)} =\n",
        "  \\sum_{c_{in}=1}^{C_{in}}   \n",
        "  \\sum_{i=1}^{K}  \n",
        "  \\sum_{j=1}^{K} \n",
        "  x_{n,c_{in},m+i-1,l+j-1}\n",
        "  w_{c_{out},c_{in},i,j}^{(conv)}\n",
        "  +\n",
        "  b_{c_{out}}^{(conv)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCGZT5IXe3kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d_scalar(x_in, conv_weight, conv_bias, device):\n",
        "    \n",
        "    #read dimentionas of input tensor and weights\n",
        "    batch_size, n_channels_in, height_in, width_in = x_in.shape\n",
        "    n_channels_out, n_channels_in, kernel_size, kernel_size = conv_weight.shape\n",
        "    \n",
        "    #calculate the dimentions of output tensor\n",
        "    height_out = height_in - kernel_size + 1\n",
        "    width_out = width_in - kernel_size + 1\n",
        "    \n",
        "    #move to device\n",
        "    x_in = x_in.to(device)\n",
        "    conv_weight = conv_weight.to(device)\n",
        "    conv_bias = conv_bias.to(device)\n",
        "    \n",
        "    #intiale output tensor of the correct size\n",
        "    z = torch.empty([batch_size,n_channels_out,height_out,width_out]).to(device)\n",
        "    \n",
        "    #fulfill z based on scalar representation\n",
        "    for n in range(batch_size):\n",
        "        for c_out in range(n_channels_out):\n",
        "            for c_in in range(n_channels_in):\n",
        "                for m in range(height_out):\n",
        "                    for l in range(width_out):\n",
        "                        z[n,c_out,m,l] = (x_in[n,c_in,m:m+kernel_size,l:l+kernel_size]*conv_weight[c_out,c_in]).sum() + conv_bias[c_out]\n",
        "                                                                                                                                                                                                                                                                                                                                                          \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKrFZet2CoTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_conv_scalar = conv2d_scalar(data, model.conv_layer.weight, model.conv_layer.bias, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuFG0H5VHDqg",
        "colab_type": "code",
        "outputId": "d2051577-244f-4e0c-aabd-3b49987f5d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_conv_scalar.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 24, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8mA9pWReEi",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Vector form of convolutional layer \n",
        "with applied 'im2col' trick on \"moving window\" level (NB! $\\mathbf{W}$ and $\\mathbf{X^{(conv)}}$ reshaped according to 'im2col' requirements):\n",
        "\\begin{equation}\n",
        "\\mathbf{Z}^{(conv)} = \\mathbf{W}\\mathbf{X}^{(conv)}+\\mathbf{B}^{(conv)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3xTKrhboF4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def im2col(X, kernel_size, device, stride = 1):\n",
        "  \n",
        "    #read dimentions of input tensor - 3-dimentional\n",
        "    C_in, S_in, S_in = X.shape\n",
        "\n",
        "    #calculate size_out\n",
        "    S_out = (S_in - kernel_size)//stride + 1\n",
        "    \n",
        "    #move to device\n",
        "    X = X.to(device)\n",
        "    \n",
        "    #intiale output tensor of the correct size\n",
        "    X_cols = torch.empty([S_out*S_out, kernel_size*kernel_size]).to(device)\n",
        "    \n",
        "    for i in range(S_out):\n",
        "        for j in range(S_out):\n",
        "            X_cols[i*S_out+j] = X[0][i: i + kernel_size, j: j + kernel_size].contiguous().view(1, -1)\n",
        "    \n",
        "    return X_cols.t() # [K*K x S_out*S_out]\n",
        "\n",
        "  \n",
        "def conv_weight2rows(conv_weight):\n",
        "    \n",
        "    ##read dimentions of input tensor\n",
        "    C_out = conv_weight.shape[0]\n",
        "    kernel_size = conv_weight.shape[2]\n",
        "    \n",
        "    #resize \n",
        "    conv_weight_rows = conv_weight.view(C_out,kernel_size*kernel_size).contiguous()\n",
        "    \n",
        "    return conv_weight_rows # [C_out x K*K]\n",
        "  \n",
        "\n",
        "def conv2d_vector(x_in, conv_weight, conv_bias, device):\n",
        "    #read dimentionas of input tensor and weights\n",
        "    batch_size, C_in, S_in, S_in = x_in.shape\n",
        "    C_out, C_in, kernel_size, kernel_size = conv_weight.shape\n",
        "    \n",
        "    #calculate the dimentions of output tensor\n",
        "    S_out = S_in - kernel_size + 1\n",
        "    \n",
        "    #move to device\n",
        "    x_in = x_in.to(device)\n",
        "    conv_weight = conv_weight.to(device)\n",
        "    conv_bias = conv_bias.to(device)\n",
        "    \n",
        "    #intiale output tensor of the correct size\n",
        "    z = torch.empty([batch_size,C_out,S_out,S_out]).to(device)\n",
        "    \n",
        "    #transformation of conv_weight\n",
        "    conv_weight_rows = conv_weight2rows(conv_weight)\n",
        "    \n",
        "    for n in range(batch_size):\n",
        "        #WconvX+b, dim(WconvX+b)=[C_out x S_out*S_out], reshape [C_out x S_out x S_out]\n",
        "        z[n] = (conv_weight_rows.matmul(im2col(x_in[n], kernel_size, device, stride=1)) + conv_bias.view(-1,1)).view(C_out,S_out,S_out)\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhvQHb33HkT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_conv_vector = conv2d_vector(data, model.conv_layer.weight, model.conv_layer.bias, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND8akTDUHwxO",
        "colab_type": "code",
        "outputId": "c243157e-9486-43d5-d631-1fbe22a5ba9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_conv_vector.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 24, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcHEwLJ4-SRT",
        "colab_type": "text"
      },
      "source": [
        "#### 1.3 PyTorch convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTb-lbX094tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_conv_torch = model.conv_layer(data.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkQTfODs9W8r",
        "colab_type": "code",
        "outputId": "34ee72e2-0ed9-4723-980f-d2ea97b89ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_conv_torch.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 24, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iy_hQ70-wCQ",
        "colab_type": "text"
      },
      "source": [
        "#### 1.4 QA: convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NjAWaNE_GXP",
        "colab_type": "code",
        "outputId": "5380bdfa-f556-4dbb-c177-1a2d7818ec53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_conv_sv = diff_mse(z_conv_scalar,z_conv_vector)\n",
        "print(\"MSE between conv2d_scalar and conv2d_vector: \", mse_conv_sv)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between conv2d_scalar and conv2d_vector:  1.485787480800583e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u80q52E8I8j5",
        "colab_type": "code",
        "outputId": "e67bf642-72ad-4e34-c608-5ee5afb66b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_conv_vt = diff_mse(z_conv_vector, z_conv_torch)\n",
        "print(\"MSE between conv2d_vector and z_conv_torch: \", mse_conv_vt)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between conv2d_vector and z_conv_torch:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vriol-27SDiA",
        "colab_type": "code",
        "outputId": "67362bb3-0c1d-4516-9234-590ecbd1468b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_conv_st = diff_mse(z_conv_scalar, z_conv_torch)\n",
        "print(\"MSE between z_conv_scalar and z_conv_torch: \", mse_conv_st)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between z_conv_scalar and z_conv_torch:  1.485787480800583e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BM-bdPqToOb",
        "colab_type": "text"
      },
      "source": [
        "#### *  to make MSE consistent, as input for the next layer for all 3 variants we will use an output from convolutional layer of native torch function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g3Nyky38dPP",
        "colab_type": "text"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6tdNlgNRz04",
        "colab_type": "text"
      },
      "source": [
        "## 2. Max-pooling layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSRfEzvR_w_c",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1 Scalar: max-pooling layer:\n",
        "\n",
        "\\begin{equation}\n",
        "z_{n,c_{in},m,l}^{(pool)} =\n",
        "max(\n",
        "  z_{n,c_{out},2i-1,2j-1}^{(conv)},\n",
        "  z_{n,c_{out},2i-1,2j}^{(conv)},\n",
        "  z_{n,c_{out},2i,2j-1}^{(conv)},\n",
        "    z_{n,c_{out},2i,2j}^{(conv)})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FxETY3RJY9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool2d_scalar(a, device, stride = 2):\n",
        "    \n",
        "    #read dimentionas of input tensor\n",
        "    batch_size, n_channels_in, height_in, width_in = a.shape\n",
        "    pooling_size = 2\n",
        "    \n",
        "    #calculate the dimentions of output tensor\n",
        "    height_out = (height_in-pooling_size)//stride + 1\n",
        "    width_out = (width_in-pooling_size)//stride + 1\n",
        "    n_channels_out = n_channels_in\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    #intiale an output tensor of the correct size\n",
        "    z = torch.empty([batch_size,n_channels_out,height_out,width_out]).to(device)\n",
        "    \n",
        "    #fulfill z based on scalar representation\n",
        "    for n in range(batch_size):\n",
        "        for c_out in range(n_channels_out):\n",
        "            for i in range(height_out):\n",
        "                for j in range(width_out):\n",
        "                    z[n,c_out,i,j] = a[n,c_out,2*i:2*i+2,2*j:2*j+2].max()\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j950JFU3RyKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_pool_scalar = pool2d_scalar(z_conv_torch, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iq0sH_GSZ2G",
        "colab_type": "code",
        "outputId": "bcac1457-e0b6-48d2-b05b-02a16647882d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_pool_scalar.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 12, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4OiBUxmmenL",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 Vector: max-pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLa564pgaC_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool2d_vector(a, device, stride = 2):\n",
        "    \n",
        "    #read dimentionas of input tensor\n",
        "    batch_size, C_in, S_in, S_in = a.shape\n",
        "    pooling_size = 2\n",
        "    stride = 2\n",
        "    \n",
        "    #calculate the dimentions of output tensor\n",
        "    S_out = (S_in - pooling_size)//stride + 1 \n",
        "    C_out = C_in\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    #intiale an output tensor of the correct size\n",
        "    z = torch.empty([batch_size,C_out,S_out,S_out]).to(device)\n",
        "    \n",
        "    for n in range(batch_size):\n",
        "        z[n] = im2col(a[n], pooling_size, device, stride=2).max(dim=0).values.view(-1, S_out, S_out)\n",
        "    return z "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czroT_7XkGi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_pool_vector = pool2d_vector(z_conv_torch, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvntPXQXkGy9",
        "colab_type": "code",
        "outputId": "d239822f-ec6b-4254-a757-31db594c3548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_pool_vector.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 12, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02sQW-asmr02",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3 PyTorch: max-pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJMjaHHfm17E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_pool_torch = F.max_pool2d(z_conv_torch, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie6p3CirnPlN",
        "colab_type": "code",
        "outputId": "a59817e9-eb48-4d01-f911-809a1cf809ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_pool_torch.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 12, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkys6fHmnTG",
        "colab_type": "text"
      },
      "source": [
        "#### 2.4 QA: max-pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0odA0ROnY_2",
        "colab_type": "code",
        "outputId": "41c21a7d-9388-4a52-c748-ee6652346635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_pool_sv = diff_mse(z_pool_scalar,z_pool_vector)\n",
        "print(\"MSE between pool2d_scalar and pool2d_vector: \", mse_pool_sv)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between pool2d_scalar and pool2d_vector:  0.13785971701145172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT7iFiFhnZMC",
        "colab_type": "code",
        "outputId": "2dc3748d-278e-4ba7-ff10-904623a62c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_pool_vt = diff_mse(z_pool_vector,z_pool_torch)\n",
        "print(\"MSE between pool2d_vector and F.max_pool2d torch: \", mse_pool_vt)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between pool2d_vector and F.max_pool2d torch:  0.13785971701145172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cepSFu2snf1T",
        "colab_type": "code",
        "outputId": "79750a26-b29d-4b59-a93a-9f71c18e3432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_pool_st = diff_mse(z_pool_scalar,z_pool_torch)\n",
        "print(\"MSE between pool2d_scalar and F.max_pool2d torch: \", mse_pool_st)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between pool2d_scalar and F.max_pool2d torch:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duuyRkZ-8Zog",
        "colab_type": "text"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azu9oF6QpCor",
        "colab_type": "text"
      },
      "source": [
        "## 3.  Reshape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNugzKm7pZ-m",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1 Scalar: reshape "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LEOjFi37aPB",
        "colab_type": "text"
      },
      "source": [
        "Scalar equation of reshape:\n",
        "\\begin{equation} \n",
        "z_{n,j}^{(reshaped)} = z_{n,c_{in},m,l}^{(pool)}\n",
        "\\end{equation} \n",
        "\n",
        "\\begin{equation} \n",
        "j = (c_{in}-1) \\ast S_{in} \\ast S_{in} + (m-1)\\ast S_{in} +l\n",
        "\\end{equation} "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qGhZvh0qj0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_scalar(a, device):\n",
        "    \n",
        "    #read dimentionas of input tensor\n",
        "    batch_size, n_channels_in, height_in, width_in = a.shape\n",
        "    \n",
        "    #calculate the dimentions of output tensor\n",
        "    n_outputs = n_channels_in * height_in * width_in\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    #intiale an output matrix of the correct size\n",
        "    z = torch.empty([batch_size, n_outputs]).to(device)\n",
        "    \n",
        "    for n in range(batch_size):\n",
        "        for c_in in range(n_channels_in):\n",
        "            for m in range(height_in):\n",
        "                for l in range(width_in):\n",
        "                    z[n,c_in*height_in*width_in+m*height_in+l] = a[n,c_in,m,l]\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MwM3Kj-qrnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_reshape_scalar = reshape_scalar(z_pool_torch, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sarVHuEBq0PR",
        "colab_type": "code",
        "outputId": "6116ccee-2e3f-4cb0-d3a5-d1f86f94f480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_reshape_scalar.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2880])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQPxL_otpiRG",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2 Vector: reshape "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo3OF9nUrCZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_vector(a, device):\n",
        "    \n",
        "    batch_size = a.shape[0]\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    z = a.clone().view(batch_size,-1)\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el97JJQdrHLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_reshape_vector = reshape_vector(z_pool_torch, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNWVITGrHaT",
        "colab_type": "code",
        "outputId": "3203114d-ae11-423c-a0bb-42ff3565e9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_reshape_vector.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2880])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0tkEWTQpnGJ",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3 PyTorch: reshape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YdFSJ7crSYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_reshape_torch = z_pool_torch.view(-1, 20 * 12 * 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvFCQOjWrSph",
        "colab_type": "code",
        "outputId": "3caefab1-3f86-455c-f680-891865ec1ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_reshape_torch.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2880])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iD144Yjrs9Z",
        "colab_type": "text"
      },
      "source": [
        "#### 3.4 QA: reshape \n",
        "Since there were only manipulations with shape MSE for all 3 functions is same as MSE of max-pooling layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLvkS2lR8Wy0",
        "colab_type": "text"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdgGKl8_vvxe",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fully-connected layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9sDin8G4ldj",
        "colab_type": "text"
      },
      "source": [
        "#### 4.1 Scalar: fully-connected layer\n",
        "\\begin{equation}\n",
        "z_{n,j}^{(fc1)} =\n",
        "  \\sum_{i=1}^{D}  \n",
        "  w_{j,i}^{(fc1)}\\ast\n",
        "  z_{n,i}^{(reshaped)}\n",
        "  +\n",
        "  b_{j}^{(fc1)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9h7t0kbwRGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc_layer_scalar(a, weight, bias, device):\n",
        "    \n",
        "    #read dimentionas of input matrix\n",
        "    batch_size, n_inputs = a.shape\n",
        "    n_outputs = bias.shape[0]\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    weight = weight.to(device)\n",
        "    bias = bias.to(device)\n",
        "    \n",
        "    #intiale an output matrix of the correct size\n",
        "    z = torch.empty([batch_size, n_outputs]).to(device)\n",
        "    \n",
        "    for n in range(batch_size):\n",
        "        for j in range(n_outputs):\n",
        "            z[n,j] = bias[j]\n",
        "            for i in range(n_inputs):\n",
        "                z[n,j] += weight[j,i]*a[n,i]\n",
        "                \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqGVgZS_wRUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_fc1_scalar = fc_layer_scalar(z_reshape_torch,model.fc_layer1.weight, model.fc_layer1.bias, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NkJIeu5wRg5",
        "colab_type": "code",
        "outputId": "6a0c7cfa-1cac-41ba-ffd8-7cfd111ddae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_fc1_scalar.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDSzugnHVyGI",
        "colab_type": "text"
      },
      "source": [
        "#### 4.2 Vector: fully-connected layer\n",
        "\\begin{equation}\n",
        "\\mathbf{Z}^{(fc1)} = \\mathbf{X}^{(reshaped)}\\mathbf{W}^{T}+\\mathbf{B}^{(fc1)}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9MMi6YsxFEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc_layer_vector(a, weight, bias, device):\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    weight = weight.to(device)\n",
        "    bias = bias.to(device)\n",
        "    \n",
        "    z = (a.matmul(weight.t())+ bias).clone()\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEO2KbiYxFQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_fc1_vector = fc_layer_scalar(z_reshape_torch, model.fc_layer1.weight, model.fc_layer1.bias, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9NBKv3_xFf3",
        "colab_type": "code",
        "outputId": "7dabd85b-2926-4094-d357-876165b5b16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_fc1_vector.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8UW_KR9xSJ3",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3 PyTorch: fully-connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okyUJbBRzvr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_fc1_torch = model.fc_layer1(z_reshape_torch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po2z0zMxzwb9",
        "colab_type": "code",
        "outputId": "1a093e7c-27d6-4659-e8c8-186adf43e19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_fc1_torch.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2hjfM6G1KEy",
        "colab_type": "text"
      },
      "source": [
        "#### 4.4 QA: fully-connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoG_ymHL1TYL",
        "colab_type": "code",
        "outputId": "b653f3e2-8f0d-4215-8be7-e866565d3f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_fc1_sv = diff_mse(z_fc1_scalar, z_fc1_vector)\n",
        "print(\"MSE between fc_layer_scalar output and fc_layer_vector: \", mse_fc1_sv)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between fc_layer_scalar output and fc_layer_vector:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P0nTZ8L2Q_k",
        "colab_type": "code",
        "outputId": "904b78d3-2604-4ac0-9b86-a725f4f78ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_fc1_st = diff_mse(z_fc1_scalar, z_fc1_torch)\n",
        "print(\"MSE between fc_layer_scalar output and model.fc_layer1 torch: \", mse_fc1_st)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between fc_layer_scalar output and model.fc_layer1 torch:  3.9590255580162007e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFDLEDB42RMj",
        "colab_type": "code",
        "outputId": "ca715a99-abbc-4e4f-d407-d609c32b4c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_fc1_vt = diff_mse(z_fc1_vector, z_fc1_torch)\n",
        "print(\"MSE between fc_layer_vector output and model.fc_layer1 torch: \", mse_fc1_vt)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between fc_layer_vector output and model.fc_layer1 torch:  3.9590255580162007e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJK5ueCC8RRg",
        "colab_type": "text"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uBJJjeYsG5_",
        "colab_type": "text"
      },
      "source": [
        "## 5. ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcmnZgjs_v4p",
        "colab_type": "text"
      },
      "source": [
        "#### 5.1 Scalar: ReLU \n",
        "\\begin{equation}\n",
        "z_{n,j}^{(relu)} =\n",
        "  relu(\n",
        "  z_{n,j}^{(fc1)})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7VgefIwJZFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_scalar(a, device):\n",
        "  \n",
        "    #read dimentionas of input matrix\n",
        "    batch_size, n_inputs = a.shape\n",
        "    \n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    #intiale an output matrix of the correct size\n",
        "    z = torch.empty(batch_size, n_inputs).to(device)\n",
        "    \n",
        "    for n in range(batch_size):\n",
        "        for i in range(n_inputs):\n",
        "            if a[n,i]<0:\n",
        "                z[n,i]=0\n",
        "            else:\n",
        "                z[n,i]=a[n,i]\n",
        "                \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqD5DqsCrrac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_relu_scalar = relu_scalar(z_fc1_torch,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO3HqDkN3CMF",
        "colab_type": "code",
        "outputId": "51691de9-e720-4d8d-93c9-575013851f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_relu_scalar.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWuQlPAy3d7C",
        "colab_type": "text"
      },
      "source": [
        "#### 5.2 Vector: ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F5e5jEfLad8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_vector(a, device):\n",
        "    #move to device\n",
        "    a = a.to(device)\n",
        "    \n",
        "    #clone input tensor\n",
        "    z = a.clone().to(device)\n",
        "    \n",
        "    #elements < 0 replace with 0\n",
        "    z[z<0] = 0\n",
        "    \n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW4FwnLg3trW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_relu_vector = relu_vector(z_fc1_torch,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtE-8qTR3znz",
        "colab_type": "code",
        "outputId": "e2fd2b9e-fb38-4667-e32a-37307b564e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_relu_vector.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sffCymIPlwk",
        "colab_type": "text"
      },
      "source": [
        "#### 5.3 PyTorch: ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leCiPDnQoKp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_relu_torch = F.relu(z_fc1_torch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91VA6jJI5Kmr",
        "colab_type": "code",
        "outputId": "b55d2604-9747-4970-b3ec-130732adc507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z_relu_torch.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7hxpFZA5P2C",
        "colab_type": "text"
      },
      "source": [
        "#### 5.4 QA: ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJCb7lj45NOI",
        "colab_type": "code",
        "outputId": "2b811953-deea-4492-aa40-444b1c554083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_relu_sv = diff_mse(z_relu_scalar, z_relu_vector)\n",
        "print(\"MSE between z_relu_scalar output and z_relu_vector: \", mse_relu_sv)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between z_relu_scalar output and z_relu_vector:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixVrcCj55tsq",
        "colab_type": "code",
        "outputId": "8c64206b-ed03-498a-9165-1df4e7396815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_relu_st = diff_mse(z_relu_scalar, z_relu_torch)\n",
        "print(\"MSE between z_relu_scalar output and F.relu torch: \", mse_relu_st)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between z_relu_scalar output and F.relu torch:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh9iZFD558Rj",
        "colab_type": "code",
        "outputId": "f8d1240f-f4e6-46fc-b7b5-41d71a33c7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse_relu_vt = diff_mse(z_relu_vector, z_relu_torch)\n",
        "print(\"MSE between z_relu_vector output and F.relu torch: \", mse_relu_vt)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between z_relu_vector output and F.relu torch:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shwdvYnsAG5G",
        "colab_type": "text"
      },
      "source": [
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k70SqMnRAKUS",
        "colab_type": "text"
      },
      "source": [
        "## Performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BB4CFHjCGjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dummy data\n",
        "#convolutional layer\n",
        "data = torch.rand([1,1,28,28]).requires_grad_(True) #batch_size=64 - crashed on fc1 layer\n",
        "w_conv = torch.rand([20,1,5,5]).requires_grad_(True)\n",
        "b_conv = torch.rand([20]).requires_grad_(True)\n",
        "\n",
        "#fc1 layer\n",
        "w_fc1 = torch.rand([500, 2880]).requires_grad_(True)\n",
        "b_fc1 = torch.rand([500]).requires_grad_(True)\n",
        "\n",
        "#fc2 layer\n",
        "w_fc2 = torch.rand([10, 500]).requires_grad_(True)\n",
        "b_fc2 = torch.rand([10]).requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A67UxHheA14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_scalar(x_in, w_conv, b_conv, w_fc1, b_fc1, w_fc2, b_fc2, device):\n",
        "    z_conv = conv2d_scalar(data, w_conv, b_conv, device)\n",
        "    z_pool = pool2d_scalar(z_conv, device)\n",
        "    z_pool_reshaped = reshape_scalar(z_pool, device)\n",
        "    z_fc1 = fc_layer_scalar(z_pool_reshaped, w_fc1, b_fc1, device)\n",
        "    z_relu = relu_scalar(z_fc1, device)\n",
        "    z_fc2 = fc_layer_scalar(z_relu, w_fc2, b_fc2, device)\n",
        "    y = F.softmax(z_fc2, dim=1)\n",
        "    return y\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fuWwEi6AHiG",
        "colab_type": "code",
        "outputId": "c5278cd3-934e-4721-dd34-53b63cf7f09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "start_scalar = time.time()\n",
        "forward_scalar(data, w_conv, b_conv, w_fc1, b_fc1, w_fc2, b_fc2, device)\n",
        "end_scalar = time.time()\n",
        "\n",
        "print(\"forward_scalar duration: \", end_scalar-start_scalar, \"sec\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_scalar duration:  86.67015671730042 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hHRFR1BByon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_vector(x_in, w_conv, b_conv, w_fc1, b_fc1, w_fc2, b_fc2, device):\n",
        "    z_conv = conv2d_vector(data, w_conv, b_conv, device)\n",
        "    z_pool = pool2d_vector(z_conv, device)\n",
        "    z_pool_reshaped = reshape_vector(z_pool, device)\n",
        "    z_fc1 = fc_layer_vector(z_pool_reshaped, w_fc1, b_fc1, device)\n",
        "    z_relu = relu_vector(z_fc1, device)\n",
        "    z_fc2 = fc_layer_vector(z_relu, w_fc2, b_fc2, device)\n",
        "    y = F.softmax(z_fc2, dim=1)\n",
        "    return y\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabKqXtDDj9G",
        "colab_type": "code",
        "outputId": "78135870-c008-420a-e665-dc50b1e6ec12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "start_vector = time.time()\n",
        "forward_vector(data, w_conv, b_conv, w_fc1, b_fc1, w_fc2, b_fc2, device)\n",
        "end_vector = time.time()\n",
        "\n",
        "print(\"forward_vector duration: \", end_vector-start_vector, \"sec\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_vector duration:  0.044803619384765625 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5X2i2fJFJ8K",
        "colab_type": "code",
        "outputId": "20001b87-74c3-48be-daf6-cc1b9abd783c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "86.67015671730042//0.044803619384765625"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1934.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sybgrrw9AiF3",
        "colab_type": "text"
      },
      "source": [
        "#### Conclusion: vector implementation on generated data performs in more than 100 times faster on CPU and about 2000 faster on CUDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "420xbjOaFcxO",
        "colab_type": "code",
        "outputId": "079b2094-98ec-4c33-8613-70eee8e755de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 21 19:56:30 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    27W /  70W |    795MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I5bgUnUG14B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}